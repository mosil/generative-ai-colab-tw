{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# RAG Engine 簡介：使用 Vertex AI 建立可擴展且模組化的 RAG 系統\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/rag-engine/intro_rag_engine.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> 在 Colab 中開啟\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fmosil%2Fgenerative-ai-colab-tw%2Frefs%2Fheads%2Fmain%2Fgemini%2Fintro_rag_engine.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在 Colab Enterprise 中開啟\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2Fmosil%2Fgenerative-ai-colab-tw%2Frefs%2Fheads%2Fmain%2Fgemini%2Fintro_rag_engine.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> 在 Vertex AI Workbench 中開啟\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/mosil/generative-ai-colab-tw/blob/main/gemini/intro_rag_engine.ipynb\">\n",
        "      <img width=\"32px\" src=\"https:///www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> 在 GitHub 上檢視\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>分享至：</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/rag-engine/intro_rag_engine.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/rag-engine/intro_rag_engine.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/rag-engine/intro_rag_engine.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/rag-engine/intro_rag_engine.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/rag-engine/intro_rag_engine.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| 作者 | [Holt Skinner](https://github.com/holtskinner) |\n",
        "| 翻譯 | [Ahdaa](https://github.com/mosil) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## 總覽\n",
        "\n",
        "檢索擴增生成 (RAG) 透過允許大型語言模型 (LLM) 在生成期間存取和處理外部資訊來源來改善它們。這確保了模型的回答基於事實數據，並避免產生幻覺。\n",
        "\n",
        "LLM 的一個常見問題是它們不理解私有知識，也就是說，您組織的資料。使用 RAG Engine，您可以豐富 LLM 的上下文，其中包含額外的私人資訊，因為該模型可以減少幻覺並更準確地回答問題。\n",
        "\n",
        "透過將額外的知識來源與 LLM 已有的知識相結合，可以提供更好的上下文。改進的上下文以及查詢增強了 LLM 回應的品質。\n",
        "\n",
        "以下概念是理解 Vertex AI RAG Engine 的關鍵。這些概念按檢索擴增生成 (RAG) 流程的順序排列。\n",
        "\n",
        "1. **資料擷取**：從不同的資料來源擷取資料。例如，本地檔案、Google Cloud Storage 和 Google Drive。\n",
        "\n",
        "2. **資料轉換**：預備索引的資料轉換。例如，資料被分割成語塊（chunks）。\n",
        "\n",
        "3. **Embedding**：將單字或文字片段轉換成數值化表示。這些數字捕捉了文字的語義以及上下文特徵。相似或是關聯度高的文字或是單字往往擁有相似的 Embedding 特徵，這意著它們在高維度的向量空間中相當地接近。\n",
        "\n",
        "4. **資料索引**：RAG Engine 建立一個稱為語料庫（corpus）的索引。這些索引建構而成知識庫，讓搜尋得以最佳化。就像是在一本大型參數書中，其詳細目錄的索引。\n",
        "\n",
        "5. **檢索**：當使用者提出問題或提供 prompt 時，RAG Engine 中的檢索元件會從知識庫中，找出和使用者提出的查詢有關之資訊。\n",
        "\n",
        "6. **生成**：檢索到的資訊，是一個會被加在使用者原始查詢的上下文中，它作為指南，讓生成式 AI 模型在可以產生基於事實且相關回應。\n",
        "\n",
        "有關更多資訊，請參閱 [Vertex AI RAG Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-overview) 的官方文件。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## 開始使用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### 安裝 Vertex AI SDK 和 Google Gen AI SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### 重新啟動執行階段\n",
        "\n",
        "若要在這個 Jupyter 執行階段中使用新安裝的套件，您必須重新啟動執行階段。您可以透過執行下方的儲存格來執行此動作，這個儲存格會重新啟動目前的 kernel。\n",
        "\n",
        "重新啟動可能需要一分鐘或更長時間。重新啟動後，請繼續進行下一步。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ 核心將會重新啟動。請等待它完成後再繼續下一步。⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### 驗證您的 notebook 環境（僅限 Colab）\n",
        "\n",
        "如果您正在 Google Colab 上執行此 notebook，請執行下方的儲存格來驗證您的環境。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### 設定 Google Cloud 專案資訊並初始化 Vertex AI SDK\n",
        "\n",
        "若要開始使用 Vertex AI，您必須擁有現有的 Google Cloud 專案並[啟用 Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
        "\n",
        "瞭解更多關於[設定專案和開發環境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)的資訊。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# 如果使用者未提供專案 ID，請使用環境變數。\n",
        "import os\n",
        "\n",
        "from google import genai\n",
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### 匯入函式庫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fc324893334"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore\n",
        "from vertexai import rag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e43229f3ad4f"
      },
      "source": [
        "### 建立 RAG Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf93d5f0ce00"
      },
      "outputs": [],
      "source": [
        "# 目前支援 Google 第一方嵌入模型\n",
        "EMBEDDING_MODEL = \"publishers/google/models/text-embedding-004\"  # @param {type:\"string\", isTemplate: true}\n",
        "\n",
        "rag_corpus = rag.create_corpus(\n",
        "    display_name=\"my-rag-corpus\",\n",
        "    backend_config=rag.RagVectorDbConfig(\n",
        "        rag_embedding_model_config=rag.RagEmbeddingModelConfig(\n",
        "            vertex_prediction_endpoint=rag.VertexPredictionEndpoint(\n",
        "                publisher_model=EMBEDDING_MODEL\n",
        "            )\n",
        "        )\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "197c585b61b2"
      },
      "source": [
        "### 檢查剛建立的語料庫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f229b13dc617"
      },
      "outputs": [],
      "source": [
        "rag.list_corpora()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c52924cc1440"
      },
      "source": [
        "### 上傳本機檔案到語料庫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4976ffe8564f"
      },
      "outputs": [],
      "source": [
        "%%writefile test.md\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by allowing them to access and incorporate external data sources when generating responses. Here's a breakdown:\n",
        "\n",
        "**What it is:**\n",
        "\n",
        "* **Combining Retrieval and Generation:**\n",
        "    * RAG combines the strengths of information retrieval systems (like search engines) with the generative power of LLMs.\n",
        "    * It enables LLMs to go beyond their pre-trained data and access up-to-date and specific information.\n",
        "* **How it works:**\n",
        "    * When a user asks a question, the RAG system first retrieves relevant information from external data sources (e.g., databases, documents, web pages).\n",
        "    * This retrieved information is then provided to the LLM as additional context.\n",
        "    * The LLM uses this augmented context to generate a more accurate and informative response.\n",
        "\n",
        "**Why it's helpful:**\n",
        "\n",
        "* **Access to Up-to-Date Information:**\n",
        "    * LLMs are trained on static datasets, so their knowledge can become outdated. RAG allows them to access real-time or frequently updated information.\n",
        "* **Improved Accuracy and Factual Grounding:**\n",
        "    * RAG reduces the risk of LLM \"hallucinations\" (generating false or misleading information) by grounding responses in verified external data.\n",
        "* **Enhanced Contextual Relevance:**\n",
        "    * By providing relevant context, RAG enables LLMs to generate more precise and tailored responses to specific queries.\n",
        "* **Increased Trust and Transparency:**\n",
        "    * RAG can provide source citations, allowing users to verify the information and increasing trust in the LLM's responses.\n",
        "* **Cost Efficiency:**\n",
        "    * Rather than constantly retraining large language models, RAG allows for the introduction of new data in a more cost effective way.\n",
        "\n",
        "In essence, RAG bridges the gap between the vast knowledge of LLMs and the need for accurate, current, and contextually relevant information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "529390917c29"
      },
      "outputs": [],
      "source": [
        "rag_file = rag.upload_file(\n",
        "    corpus_name=rag_corpus.name,\n",
        "    path=\"test.md\",\n",
        "    display_name=\"test.md\",\n",
        "    description=\"my test file\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5269a0c2786d"
      },
      "source": [
        "### 從 Google Cloud Storage 匯入檔案\n",
        "\n",
        "請記得為您的 Google Cloud Storage bucket，授予「檢視者」存取權給「Vertex RAG 資料服務代理程式」（格式為 `service-{project_number}@gcp-sa-vertex-rag.iam.gserviceaccount.com`）。\n",
        "\n",
        "在本範例中，我們會使用包含 Alphabet 收益報告的公開 GCS bucket。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5910ae450f69"
      },
      "outputs": [],
      "source": [
        "INPUT_GCS_BUCKET = (\n",
        "    \"gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/\"\n",
        ")\n",
        "\n",
        "response = rag.import_files(\n",
        "    corpus_name=rag_corpus.name,\n",
        "    paths=[INPUT_GCS_BUCKET],\n",
        "    # Optional\n",
        "    transformation_config=rag.TransformationConfig(\n",
        "        chunking_config=rag.ChunkingConfig(chunk_size=1024, chunk_overlap=100)\n",
        "    ),\n",
        "    max_embedding_requests_per_min=900,  # Optional\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60a84095746d"
      },
      "source": [
        "### 從 Google Drive 匯入檔案\n",
        "\n",
        "符合資格的路徑可以格式化為：\n",
        "\n",
        "- `https://drive.google.com/drive/folders/{folder_id}`\n",
        "- `https://drive.google.com/file/d/{file_id}`。\n",
        "\n",
        "請記得為您的 Drive 資料夾/檔案，授予「檢視者」存取權給「Vertex RAG 資料服務代理程式」（格式為 `service-{project_number}@gcp-sa-vertex-rag.iam.gserviceaccount.com`）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a90c125874c"
      },
      "outputs": [],
      "source": [
        "response = rag.import_files(\n",
        "    corpus_name=rag_corpus.name,\n",
        "    paths=[\"https://drive.google.com/drive/folders/{folder_id}\"],\n",
        "    # Optional\n",
        "    transformation_config=rag.TransformationConfig(\n",
        "        chunking_config=rag.ChunkingConfig(chunk_size=512, chunk_overlap=50)\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f700b3e23121"
      },
      "source": [
        "### 可選：執行直接上下文檢索"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4669c5cdbb5a"
      },
      "outputs": [],
      "source": [
        "# 直接上下文檢索\n",
        "response = rag.retrieval_query(\n",
        "    rag_resources=[\n",
        "        rag.RagResource(\n",
        "            rag_corpus=rag_corpus.name,\n",
        "            # Optional: supply IDs from `rag.list_files()`.\n",
        "            # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
        "        )\n",
        "    ],\n",
        "    rag_retrieval_config=rag.RagRetrievalConfig(\n",
        "        top_k=10,  # Optional\n",
        "        filter=rag.Filter(\n",
        "            vector_distance_threshold=0.5,  # Optional\n",
        "        ),\n",
        "    ),\n",
        "    text=\"什麼是 RAG 以及它為何有用？\",\n",
        ")\n",
        "print(response)\n",
        "\n",
        "# Optional: The retrieved context can be passed to any SDK or model generation API to generate final results.\n",
        "# context = \" \".join([context.text for context in response.contexts.contexts]).replace(\"\\n\", \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79ea89661842"
      },
      "source": [
        "### 建立 RAG 檢索工具"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ebceac3d816"
      },
      "outputs": [],
      "source": [
        "# 為 RAG Corpus 建立工具\n",
        "rag_retrieval_tool = Tool(\n",
        "    retrieval=Retrieval(\n",
        "        vertex_rag_store=VertexRagStore(\n",
        "            rag_corpora=[rag_corpus.name],\n",
        "            similarity_top_k=10,\n",
        "            vector_distance_threshold=0.5,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d88fa7ede853"
      },
      "source": [
        "### 使用 RAG 檢索工具，透過 Gemini 生成內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dd928baecd4"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "124b36be8d5b"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"什麼是 RAG？\",\n",
        "    config=GenerateContentConfig(tools=[rag_retrieval_tool]),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0268fe43d41c"
      },
      "source": [
        "### 使用 RAG 檢索工具，透過 Llama3 生成內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6e67ee7968c"
      },
      "outputs": [],
      "source": [
        "from vertexai import generative_models\n",
        "\n",
        "# 將工具載入 Llama 模型\n",
        "rag_retrieval_tool = generative_models.Tool.from_retrieval(\n",
        "    retrieval=rag.Retrieval(\n",
        "        source=rag.VertexRagStore(\n",
        "            rag_resources=[rag.RagResource(rag_corpus=rag_corpus.name)],\n",
        "            rag_retrieval_config=rag.RagRetrievalConfig(\n",
        "                top_k=10,  # Optional\n",
        "                filter=rag.Filter(\n",
        "                    vector_distance_threshold=0.5,  # Optional\n",
        "                ),\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        ")\n",
        "\n",
        "llama_model = generative_models.GenerativeModel(\n",
        "    # 您的 Llama3 自行部署端點\n",
        "    \"projects/{project}/locations/{location}/endpoints/{endpoint_resource_id}\",\n",
        "    tools=[rag_retrieval_tool],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6d710b6dece"
      },
      "outputs": [],
      "source": [
        "response = llama_model.generate_content(\"什麼是 RAG？\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_rag_engine.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
